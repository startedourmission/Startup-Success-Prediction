{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 923 entries, 0 to 922\n",
      "Data columns (total 49 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0                923 non-null    int64  \n",
      " 1   state_code                923 non-null    object \n",
      " 2   latitude                  923 non-null    float64\n",
      " 3   longitude                 923 non-null    float64\n",
      " 4   zip_code                  923 non-null    object \n",
      " 5   id                        923 non-null    object \n",
      " 6   city                      923 non-null    object \n",
      " 7   Unnamed: 6                430 non-null    object \n",
      " 8   name                      923 non-null    object \n",
      " 9   labels                    923 non-null    int64  \n",
      " 10  founded_at                923 non-null    object \n",
      " 11  closed_at                 335 non-null    object \n",
      " 12  first_funding_at          923 non-null    object \n",
      " 13  last_funding_at           923 non-null    object \n",
      " 14  age_first_funding_year    923 non-null    float64\n",
      " 15  age_last_funding_year     923 non-null    float64\n",
      " 16  age_first_milestone_year  771 non-null    float64\n",
      " 17  age_last_milestone_year   771 non-null    float64\n",
      " 18  relationships             923 non-null    int64  \n",
      " 19  funding_rounds            923 non-null    int64  \n",
      " 20  funding_total_usd         923 non-null    int64  \n",
      " 21  milestones                923 non-null    int64  \n",
      " 22  state_code.1              922 non-null    object \n",
      " 23  is_CA                     923 non-null    int64  \n",
      " 24  is_NY                     923 non-null    int64  \n",
      " 25  is_MA                     923 non-null    int64  \n",
      " 26  is_TX                     923 non-null    int64  \n",
      " 27  is_otherstate             923 non-null    int64  \n",
      " 28  category_code             923 non-null    object \n",
      " 29  is_software               923 non-null    int64  \n",
      " 30  is_web                    923 non-null    int64  \n",
      " 31  is_mobile                 923 non-null    int64  \n",
      " 32  is_enterprise             923 non-null    int64  \n",
      " 33  is_advertising            923 non-null    int64  \n",
      " 34  is_gamesvideo             923 non-null    int64  \n",
      " 35  is_ecommerce              923 non-null    int64  \n",
      " 36  is_biotech                923 non-null    int64  \n",
      " 37  is_consulting             923 non-null    int64  \n",
      " 38  is_othercategory          923 non-null    int64  \n",
      " 39  object_id                 923 non-null    object \n",
      " 40  has_VC                    923 non-null    int64  \n",
      " 41  has_angel                 923 non-null    int64  \n",
      " 42  has_roundA                923 non-null    int64  \n",
      " 43  has_roundB                923 non-null    int64  \n",
      " 44  has_roundC                923 non-null    int64  \n",
      " 45  has_roundD                923 non-null    int64  \n",
      " 46  avg_participants          923 non-null    float64\n",
      " 47  is_top500                 923 non-null    int64  \n",
      " 48  status                    923 non-null    object \n",
      "dtypes: float64(7), int64(28), object(14)\n",
      "memory usage: 353.5+ KB\n",
      "None\n",
      "        Unnamed: 0    latitude   longitude      labels  \\\n",
      "count   923.000000  923.000000  923.000000  923.000000   \n",
      "mean    572.297941   38.517442 -103.539212    0.646804   \n",
      "std     333.585431    3.741497   22.394167    0.478222   \n",
      "min       1.000000   25.752358 -122.756956    0.000000   \n",
      "25%     283.500000   37.388869 -122.198732    0.000000   \n",
      "50%     577.000000   37.779281 -118.374037    1.000000   \n",
      "75%     866.500000   40.730646  -77.214731    1.000000   \n",
      "max    1153.000000   59.335232   18.057121    1.000000   \n",
      "\n",
      "       age_first_funding_year  age_last_funding_year  \\\n",
      "count              923.000000             923.000000   \n",
      "mean                 2.235630               3.931456   \n",
      "std                  2.510449               2.967910   \n",
      "min                 -9.046600              -9.046600   \n",
      "25%                  0.576700               1.669850   \n",
      "50%                  1.446600               3.528800   \n",
      "75%                  3.575350               5.560250   \n",
      "max                 21.895900              21.895900   \n",
      "\n",
      "       age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "count                771.000000               771.000000     923.000000   \n",
      "mean                   3.055353                 4.754423       7.710726   \n",
      "std                    2.977057                 3.212107       7.265776   \n",
      "min                  -14.169900                -7.005500       0.000000   \n",
      "25%                    1.000000                 2.411000       3.000000   \n",
      "50%                    2.520500                 4.476700       5.000000   \n",
      "75%                    4.686300                 6.753400      10.000000   \n",
      "max                   24.684900                24.684900      63.000000   \n",
      "\n",
      "       funding_rounds  ...  is_consulting  is_othercategory      has_VC  \\\n",
      "count      923.000000  ...     923.000000        923.000000  923.000000   \n",
      "mean         2.310943  ...       0.003250          0.322860    0.326111   \n",
      "std          1.390922  ...       0.056949          0.467823    0.469042   \n",
      "min          1.000000  ...       0.000000          0.000000    0.000000   \n",
      "25%          1.000000  ...       0.000000          0.000000    0.000000   \n",
      "50%          2.000000  ...       0.000000          0.000000    0.000000   \n",
      "75%          3.000000  ...       0.000000          1.000000    1.000000   \n",
      "max         10.000000  ...       1.000000          1.000000    1.000000   \n",
      "\n",
      "        has_angel  has_roundA  has_roundB  has_roundC  has_roundD  \\\n",
      "count  923.000000  923.000000  923.000000  923.000000  923.000000   \n",
      "mean     0.254605    0.508126    0.392199    0.232936    0.099675   \n",
      "std      0.435875    0.500205    0.488505    0.422931    0.299729   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    1.000000    0.000000    0.000000    0.000000   \n",
      "75%      1.000000    1.000000    1.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       avg_participants   is_top500  \n",
      "count        923.000000  923.000000  \n",
      "mean           2.838586    0.809317  \n",
      "std            1.874601    0.393052  \n",
      "min            1.000000    0.000000  \n",
      "25%            1.500000    1.000000  \n",
      "50%            2.500000    1.000000  \n",
      "75%            3.800000    1.000000  \n",
      "max           16.000000    1.000000  \n",
      "\n",
      "[8 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"startup_data.csv\")\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 현황:\n",
      "Unnamed: 6                  493\n",
      "closed_at                   588\n",
      "age_first_milestone_year    152\n",
      "age_last_milestone_year     152\n",
      "state_code.1                  1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "결측치 처리 후 현황:\n",
      "Unnamed: 6      493\n",
      "closed_at       588\n",
      "state_code.1      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    # 결측치 현황 확인\n",
    "    missing_info = df.isnull().sum()\n",
    "    print(\"결측치 현황:\")\n",
    "    print(missing_info[missing_info > 0])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 마일스톤 관련 결측치 처리\n",
    "    df['age_first_milestone_year'] = df['age_first_milestone_year'].fillna(0)\n",
    "    df['age_last_milestone_year'] = df['age_last_milestone_year'].fillna(0)\n",
    "    \n",
    "    # 결측치 처리 후 확인\n",
    "    missing_after = df.isnull().sum()\n",
    "    print(\"결측치 처리 후 현황:\")\n",
    "    print(missing_after[missing_after > 0])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "main_columns = [\n",
    "    # 위치 관련\n",
    "    'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate',\n",
    "    \n",
    "    # 기업 기본 정보\n",
    "    'founded_at', #'closed_at',\n",
    "    \n",
    "    # 펀딩 관련 정보\n",
    "    'first_funding_at', 'last_funding_at',\n",
    "    'age_first_funding_year', 'age_last_funding_year',\n",
    "    'funding_rounds', 'funding_total_usd',\n",
    "    'avg_participants',\n",
    "    \n",
    "    # 투자 유형\n",
    "    'has_VC', 'has_angel', 'has_roundA', 'has_roundB', \n",
    "    'has_roundC', 'has_roundD',\n",
    "    \n",
    "    # 마일스톤 관련\n",
    "    'milestones', 'age_first_milestone_year', \n",
    "    'age_last_milestone_year',\n",
    "    \n",
    "    # 비즈니스 관계\n",
    "    'relationships',\n",
    "    \n",
    "    # 산업 분류\n",
    "    'is_software', 'is_web', 'is_mobile', 'is_enterprise',\n",
    "    'is_advertising', 'is_gamesvideo', 'is_ecommerce',\n",
    "    'is_biotech', 'is_consulting', 'is_othercategory'\n",
    "]\n",
    "\n",
    "df = handle_missing_values(df.copy())\n",
    "\n",
    "target_columns = ['is_top500', 'labels']\n",
    "\n",
    "date_cols = ['founded_at', 'first_funding_at', 'last_funding_at'] # close_at은 위에서 제거됨\n",
    "\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col]).astype(np.int64) // 10**9\n",
    "\n",
    "X = df[main_columns].copy().reset_index(drop=True)\n",
    "y = df[target_columns].copy().reset_index(drop=True)\n",
    "\n",
    "target = 'labels' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def plot_model_evaluation(y_test, y_pred, y_pred_proba, features, importance):\n",
    "\n",
    "    if y_pred_proba.ndim == 2:\n",
    "        y_pred_proba = y_pred_proba[:, 1]\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': list(features),\n",
    "        'importance': list(importance)\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('importance', ascending=True)\n",
    "    \n",
    "    plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "    plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.style.use('default')  # 기본 스타일로 초기화\n",
    "    plt.rcParams['figure.facecolor'] = 'white'\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"AUC :\", roc_auc)\n",
    "\n",
    "    print(\"\\n상위 중요 특성:\")\n",
    "    print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(\n\u001b[1;32m      4\u001b[0m     X, y[target], \n\u001b[1;32m      5\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m xgb \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     10\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     11\u001b[0m     use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m xgb\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y[target], \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plot_model_evaluation(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_pred_proba=xgb.predict_proba(X_test),  \n",
    "    features=importance['feature'],          \n",
    "    importance=importance['importance']      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간순 정렬\n",
    "\n",
    "X_sort = X.sort_values('founded_at')\n",
    "y = y.reindex(X_sort.index)  \n",
    "\n",
    "split_idx = int(len(X_sort) * 0.8)\n",
    "X_train = X_sort[:split_idx]\n",
    "X_test = X_sort[split_idx:]\n",
    "y_train = y[target][:split_idx]  \n",
    "y_test = y[target][split_idx:]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_sort = XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_sort.fit(X_train, y_train)\n",
    "y_pred = xgb_sort.predict(X_test)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_sort.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plot_model_evaluation(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_pred_proba=xgb_sort.predict_proba(X_test),  \n",
    "    features=importance['feature'],          \n",
    "    importance=importance['importance']      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({1: 495, 0: 243})\n",
      "After SMOTE: Counter({0: 495, 1: 495})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# SMOTE는 훈련 데이터에만 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", Counter(y_train))\n",
    "print(\"After SMOTE:\", Counter(y_train_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train_balanced = X_train_balanced.sort_values('founded_at').reset_index(drop=True)\n",
    "y_train_balanced = y_train_balanced[target].reindex(X.index)\n",
    "\n",
    "xgb_smote = XGBClassifier(\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_smote.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = xgb_smote.predict(X_test)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_smote.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plot_model_evaluation(\n",
    "    y_test=y_test,\n",
    "    y_pred=y_pred,\n",
    "    y_pred_proba=xgb.predict_proba(X_test),  \n",
    "    features=importance['feature'],          \n",
    "    importance=importance['importance']      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "def evaluate_model_with_time_cv(model, X, y, n_splits=5):\n",
    "   # 시간순 정렬\n",
    "   X = X.sort_values('founded_at').reset_index(drop=True)\n",
    "   y = y.reindex(X.index)\n",
    "   \n",
    "   # TimeSeriesSplit \n",
    "   tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "   scores = []\n",
    "   \n",
    "   for train_idx, val_idx in tscv.split(X):\n",
    "       # Split\n",
    "       X_train_fold = X.iloc[train_idx]\n",
    "       X_val_fold = X.iloc[val_idx]\n",
    "       y_train_fold = y.iloc[train_idx]\n",
    "       y_val_fold = y.iloc[val_idx]\n",
    "       \n",
    "       # Train & Predict\n",
    "       model.fit(X_train_fold, y_train_fold)\n",
    "       y_pred = model.predict(X_val_fold)\n",
    "       \n",
    "       # Score\n",
    "       scores.append(f1_score(y_val_fold, y_pred))\n",
    "   \n",
    "   print(f\"F1 scores: {scores}\")\n",
    "   print(f\"Mean F1: {np.mean(scores):.3f} (+/- {np.std(scores) * 2:.3f})\")\n",
    "   \n",
    "   return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 모델에 대해 평가\n",
    "scores_xgb1 = evaluate_model_with_time_cv(xgb, X, y[target])\n",
    "scores_xgb2 = evaluate_model_with_time_cv(xgb_sort, X, y[target])\n",
    "scores_xgb3 = evaluate_model_with_time_cv(xgb_smote, X, y[target])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
